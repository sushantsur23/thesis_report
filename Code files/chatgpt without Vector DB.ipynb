{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\susha\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'id'],\n",
      "        num_rows: 918\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset with the \"question-answer\" configuration\n",
    "dataset1 = load_dataset('rag-datasets/rag-mini-wikipedia', 'question-answer')\n",
    "\n",
    "df1 = pd.DataFrame(dataset1['test'])\n",
    "# Display the dataset\n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did his mother die of pneumonia?</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many long was Lincoln's formal education?</td>\n",
       "      <td>18 months</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When did Lincoln begin his political career?</td>\n",
       "      <td>1832</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Was Wilson president of the American Political...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Did he not cast his ballot for John M. Palmer ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>Did Wilson not spend 1914 through the beginnin...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Was Wilson , a staunch opponent of antisemitis...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>What happened in 1917?</td>\n",
       "      <td>raised billions through Liberty loans, imposed...</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Was Abraham Lincoln the sixteenth President of...   \n",
       "1    Did Lincoln sign the National Banking Act of 1...   \n",
       "2                     Did his mother die of pneumonia?   \n",
       "3        How many long was Lincoln's formal education?   \n",
       "4         When did Lincoln begin his political career?   \n",
       "..                                                 ...   \n",
       "913  Was Wilson president of the American Political...   \n",
       "914  Did he not cast his ballot for John M. Palmer ...   \n",
       "915  Did Wilson not spend 1914 through the beginnin...   \n",
       "916  Was Wilson , a staunch opponent of antisemitis...   \n",
       "917                             What happened in 1917?   \n",
       "\n",
       "                                                answer    id  \n",
       "0                                                  yes     0  \n",
       "1                                                  yes     2  \n",
       "2                                                   no     4  \n",
       "3                                            18 months     6  \n",
       "4                                                 1832     8  \n",
       "..                                                 ...   ...  \n",
       "913                                                Yes  1710  \n",
       "914                                                Yes  1711  \n",
       "915                                                Yes  1712  \n",
       "916                                                Yes  1713  \n",
       "917  raised billions through Liberty loans, imposed...  1714  \n",
       "\n",
       "[918 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question is  What happened in 1917?\n",
      "answer is raised billions through Liberty loans, imposed an income tax, S08_set up the War Industries Board, promoted labor union growth, supervised agriculture and food production through the Lever Act, took over control of the railroads, and suppressed anti-war movements\n"
     ]
    }
   ],
   "source": [
    "question = df1['question'][917]\n",
    "print(\"Question is \",question)\n",
    "answer  = df1['answer'][917]\n",
    "print(\"answer is\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question is  How many long was Lincoln's formal education?\n",
      "answer is 18 months\n"
     ]
    }
   ],
   "source": [
    "question1 = df1['question'][3]\n",
    "print(\"Question is \",question1)\n",
    "answer1  = df1['answer'][3]\n",
    "print(\"answer is\",answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def answer_question(text, model=\"gpt-4o-mini\", max_tokens=100):\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in giving the most accurate answer for a specific question asked.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\\n{text}\"}\n",
    "        ]\n",
    "        )\n",
    "        # Extract the summary from the response\n",
    "        summary = response.choices[0].message.content\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Several significant events occurred in 1917, including:\n",
      "\n",
      "1. **Russian Revolution**: The February Revolution led to the abdication of Tsar Nicholas II and the end of the Romanov dynasty. This was followed by the October Revolution, in which the Bolsheviks, led by Vladimir Lenin, seized power from the provisional government.\n",
      "\n",
      "2. **United States Entry into World War I**: The United States declared war on Germany on April 6, 1917, joining the Allied Powers in World War I after years of neutrality.\n",
      "\n",
      "3. **Balfour Declaration**: On November 2, 1917, the British government issued the Balfour Declaration, expressing support for a \"national home for the Jewish people\" in Palestine, which became a pivotal moment in Middle Eastern history.\n",
      "\n",
      "4. **Battle of Passchendaele**: This significant and grueling battle took place during the summer and fall of 1917 as part of the Flanders campaign in World War I, marked by heavy casualties and harsh conditions.\n",
      "\n",
      "These events had lasting impacts on global politics, society, and the course of history.\n"
     ]
    }
   ],
   "source": [
    "result = answer_question(text = question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROUGE-1': 0.08823529411764705, 'ROUGE-2': 0.009900990099009901, 'ROUGE-L': 0.06862745098039215}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge(reference, candidate):\n",
    "\n",
    "    # Initialize a ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, candidate)\n",
    "    \n",
    "    # Extract and format the scores\n",
    "    rouge_scores = {\n",
    "        'ROUGE-1': scores['rouge1'].fmeasure,\n",
    "        'ROUGE-2': scores['rouge2'].fmeasure,\n",
    "        'ROUGE-L': scores['rougeL'].fmeasure\n",
    "    }\n",
    "    \n",
    "    return rouge_scores\n",
    "\n",
    "print(calculate_rouge(reference = answer,candidate = result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate rougue score for next question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is  Abraham Lincoln had a limited formal education, totaling about 18 months. His schooling was sporadic, as he grew up in rural areas where access to formal education was limited. Most of his learning came from self-education through reading books and engaging in discussions.\n",
      "{'ROUGE-1': 0.08695652173913045, 'ROUGE-2': 0.04545454545454545, 'ROUGE-L': 0.08695652173913045}\n"
     ]
    }
   ],
   "source": [
    "result1 = answer_question(text = question1)\n",
    "print(\"Result is \",result1)\n",
    "print(calculate_rouge(reference = answer1,candidate = result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.0032728749416290007\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def calculate_bleu(reference, candidate):\n",
    "    \n",
    "    # Tokenize the reference and candidate texts\n",
    "    reference_tokens = [reference.split()]\n",
    "    candidate_tokens = candidate.split()\n",
    "    \n",
    "    # Apply smoothing to handle edge cases\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    \n",
    "    # Compute BLEU score\n",
    "    bleu_score = sentence_bleu(\n",
    "        reference_tokens,\n",
    "        candidate_tokens,\n",
    "        smoothing_function=smoothing_function\n",
    "    )\n",
    "    \n",
    "    return bleu_score\n",
    "bleu = calculate_bleu(reference = answer, candidate=result)\n",
    "print(\"BLEU Score:\", bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.008647922020227043\n"
     ]
    }
   ],
   "source": [
    "bleu = calculate_bleu(reference = answer1, candidate=result1)\n",
    "print(\"BLEU Score:\", bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "# from nltk import word_tokenize\n",
    "\n",
    "# def calculate_bleu_score_from_strings(reference_summary_str, generated_summary_str):\n",
    "\n",
    "#     # Tokenize the strings into lists of words\n",
    "#     reference_summary = [word_tokenize(sentence) for sentence in reference_summary_str.split('.')] \n",
    "#     generated_summary = word_tokenize(generated_summary_str) \n",
    "\n",
    "#     return sentence_bleu(reference_summary, generated_summary)\n",
    "\n",
    "# # Example Usage:\n",
    "# reference_summary_str = first_answer\n",
    "# generated_summary_str = result\n",
    "\n",
    "# bleu_score = calculate_bleu_score_from_strings(reference_summary_str, generated_summary_str)\n",
    "# print(f\"BLEU Score: {bleu_score}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
